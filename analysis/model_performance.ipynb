{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: In a python notebook called analysis/model_performance.ipynb write scripts to train and evaluate models for model selection using data generated by your Data Pipeline (See Assignment 2). Your notebook should train and store three sklearn models (e.g., Logistic Regression, Support Vector Machines, Random Forest, etc.). Feel free to modify your previous submissions if you see fit. Store your models in storage/models/artifacts/.\n",
    "\n",
    "NOTE: For the case study submission, you will be asked to thoroughly defend the methods (i.e., metrics, data partitioning, analysis, etc.) used to evaluate and select your models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'version': 'v1.0',\n",
       " 'storage': 'securebank/storage/raw_data/',\n",
       " 'description': {'shape': (1647542, 26),\n",
       "  'columns': ['index_x',\n",
       "   'trans_date_trans_time',\n",
       "   'cc_num',\n",
       "   'unix_time',\n",
       "   'merchant',\n",
       "   'category',\n",
       "   'amt',\n",
       "   'merch_lat',\n",
       "   'merch_long',\n",
       "   'index_y',\n",
       "   'first',\n",
       "   'last',\n",
       "   'sex',\n",
       "   'street',\n",
       "   'city',\n",
       "   'state',\n",
       "   'zip',\n",
       "   'lat',\n",
       "   'long',\n",
       "   'city_pop',\n",
       "   'job',\n",
       "   'dob',\n",
       "   'is_fraud',\n",
       "   'hour',\n",
       "   'day_of_week',\n",
       "   'month'],\n",
       "  'dtypes': {'index_x': dtype('int64'),\n",
       "   'trans_date_trans_time': dtype('<M8[ns]'),\n",
       "   'cc_num': dtype('int64'),\n",
       "   'unix_time': dtype('float64'),\n",
       "   'merchant': dtype('O'),\n",
       "   'category': dtype('O'),\n",
       "   'amt': dtype('float64'),\n",
       "   'merch_lat': dtype('float64'),\n",
       "   'merch_long': dtype('float64'),\n",
       "   'index_y': dtype('int64'),\n",
       "   'first': dtype('O'),\n",
       "   'last': dtype('O'),\n",
       "   'sex': dtype('O'),\n",
       "   'street': dtype('O'),\n",
       "   'city': dtype('O'),\n",
       "   'state': dtype('O'),\n",
       "   'zip': dtype('float64'),\n",
       "   'lat': dtype('float64'),\n",
       "   'long': dtype('float64'),\n",
       "   'city_pop': dtype('float64'),\n",
       "   'job': dtype('O'),\n",
       "   'dob': dtype('<M8[ns]'),\n",
       "   'is_fraud': dtype('float64'),\n",
       "   'hour': dtype('int32'),\n",
       "   'day_of_week': dtype('int32'),\n",
       "   'month': dtype('int32')},\n",
       "  'missing_values': {'index_x': 0,\n",
       "   'trans_date_trans_time': 0,\n",
       "   'cc_num': 0,\n",
       "   'unix_time': 164868,\n",
       "   'merchant': 164649,\n",
       "   'category': 164959,\n",
       "   'amt': 0,\n",
       "   'merch_lat': 0,\n",
       "   'merch_long': 0,\n",
       "   'index_y': 0,\n",
       "   'first': 0,\n",
       "   'last': 0,\n",
       "   'sex': 0,\n",
       "   'street': 0,\n",
       "   'city': 0,\n",
       "   'state': 0,\n",
       "   'zip': 0,\n",
       "   'lat': 0,\n",
       "   'long': 0,\n",
       "   'city_pop': 0,\n",
       "   'job': 0,\n",
       "   'dob': 0,\n",
       "   'is_fraud': 0,\n",
       "   'hour': 0,\n",
       "   'day_of_week': 0,\n",
       "   'month': 0},\n",
       "  'fraud_ratio': 0.003942843338743413}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Get the feature extractor\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(parent_dir)\n",
    "from modules.raw_data_handler import Raw_Data_Handler\n",
    "from modules.dataset_design import Dataset_Designer\n",
    "from modules.feature_extractor import Feature_Extractor\n",
    "\n",
    "raw_data_handler = Raw_Data_Handler()\n",
    "raw_data_handler.extract(customer_information_filename = \"../data_sources/customer_release.csv\", transaction_filename=\"../data_sources/transactions_release.parquet\", fraud_information_filename=\"../data_sources/fraud_release.json\")\n",
    "raw_data_handler.transform()\n",
    "raw_data_handler.load('v1.0')\n",
    "raw_data_handler.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'version': 'v1.0',\n",
       " 'storage': 'securebank/storage/partitioned_data/',\n",
       " 'description': {'train': {'data_type': 'train',\n",
       "   'shape': (1336691, 26),\n",
       "   'fraud_ratio': 0.0038931959592755543,\n",
       "   'unique_cc_nums': 600},\n",
       "  'test': {'data_type': 'test',\n",
       "   'shape': (310851, 26),\n",
       "   'fraud_ratio': 0.004156332133401533,\n",
       "   'unique_cc_nums': 150}}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_designer = Dataset_Designer()\n",
    "dataset_designer.extract('v1.0')\n",
    "dataset_designer.sample()\n",
    "dataset_designer.load('v1.0')\n",
    "dataset_designer.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'version': 'v1.0',\n",
       " 'storage': 'securebank/storage/features/',\n",
       " 'description': {'train_features': {'shape': (1336691, 9),\n",
       "   'columns': ['category',\n",
       "    'merchant',\n",
       "    'merch_lat',\n",
       "    'merch_long',\n",
       "    'hour_sin',\n",
       "    'hour_cos',\n",
       "    'log_amt',\n",
       "    'rapid_transactions',\n",
       "    'distance'],\n",
       "   'dtypes': {'category': dtype('float64'),\n",
       "    'merchant': dtype('float64'),\n",
       "    'merch_lat': dtype('float64'),\n",
       "    'merch_long': dtype('float64'),\n",
       "    'hour_sin': dtype('float64'),\n",
       "    'hour_cos': dtype('float64'),\n",
       "    'log_amt': dtype('float64'),\n",
       "    'rapid_transactions': dtype('float64'),\n",
       "    'distance': dtype('float64')},\n",
       "   'null_count': {'category': 0,\n",
       "    'merchant': 0,\n",
       "    'merch_lat': 0,\n",
       "    'merch_long': 0,\n",
       "    'hour_sin': 0,\n",
       "    'hour_cos': 0,\n",
       "    'log_amt': 0,\n",
       "    'rapid_transactions': 0,\n",
       "    'distance': 0}},\n",
       "  'train_target': {'shape': (1336691, 1),\n",
       "   'columns': ['is_fraud'],\n",
       "   'dtypes': {'is_fraud': dtype('float64')},\n",
       "   'null_count': {'is_fraud': 0}},\n",
       "  'test_features': {'shape': (310851, 9),\n",
       "   'columns': ['category',\n",
       "    'merchant',\n",
       "    'merch_lat',\n",
       "    'merch_long',\n",
       "    'hour_sin',\n",
       "    'hour_cos',\n",
       "    'log_amt',\n",
       "    'rapid_transactions',\n",
       "    'distance'],\n",
       "   'dtypes': {'category': dtype('float64'),\n",
       "    'merchant': dtype('float64'),\n",
       "    'merch_lat': dtype('float64'),\n",
       "    'merch_long': dtype('float64'),\n",
       "    'hour_sin': dtype('float64'),\n",
       "    'hour_cos': dtype('float64'),\n",
       "    'log_amt': dtype('float64'),\n",
       "    'rapid_transactions': dtype('float64'),\n",
       "    'distance': dtype('float64')},\n",
       "   'null_count': {'category': 0,\n",
       "    'merchant': 0,\n",
       "    'merch_lat': 0,\n",
       "    'merch_long': 0,\n",
       "    'hour_sin': 0,\n",
       "    'hour_cos': 0,\n",
       "    'log_amt': 0,\n",
       "    'rapid_transactions': 0,\n",
       "    'distance': 0}},\n",
       "  'test_target': {'shape': (310851, 1),\n",
       "   'columns': ['is_fraud'],\n",
       "   'dtypes': {'is_fraud': dtype('float64')},\n",
       "   'null_count': {'is_fraud': 0}}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor = Feature_Extractor()\n",
    "feature_extractor.extract('v1.0_train', 'v1.0_test')\n",
    "feature_extractor.transform()\n",
    "feature_extractor.load('v1.0')\n",
    "feature_extractor.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform features\n",
    "partitioned_data = feature_extractor.transform()\n",
    "\n",
    "# Prepare features and target\n",
    "X_train, y_train, X_test, y_test = partitioned_data[0], partitioned_data[1], partitioned_data[2], partitioned_data[3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Metrics Used (Accuracy, Precision, Recall, F1 Score)**\n",
    "\n",
    "We employed four key metrics to evaluate our models: accuracy, precision, recall, and F1 score. Accuracy provides an overall view of how many predictions the model got right, but it can be misleading in imbalanced datasets. For this reason, we also used precision and recall to gain a more detailed understanding of the model's performance. Precision is essential when false positives need to be minimized, especially in fraud detection, where falsely flagging normal cases can lead to worse customer experience. On the other hand, recall is crucial when missing true positives could have serious consequences. The F1 score, which balances precision and recall, is an excellent metric for handling imbalanced datasets since it combines both into a single score. By using the F1 score to select the best model, we ensure that the chosen model minimizes both false positives and false negatives.\n",
    "\n",
    "#### **Model Selection (Logistic Regression, SVM, Random Forest)**\n",
    "\n",
    "Three models were selected for evaluation: Logistic Regression, Support Vector Machine (SVM), and Random Forest. Logistic Regression was chosen as a baseline model due to its simplicity and interpretability. While not necessarily the most powerful, it serves as a solid reference point for comparison. SVM was selected for its ability to model complex relationships in high-dimensional spaces, which makes it useful for binary classification tasks where clear margins between classes exist. Random Forest, as an ensemble method, can model complex feature interactions and is resistant to overfitting. Its ability to handle non-linear relationships makes it suitable for more complex problems. Additionally, Random Forest provides feature importance scores, which are useful for interpretability and feature selection.\n",
    "\n",
    "#### **Final Model Selection Based on F1 Score**\n",
    "\n",
    "The F1 score was chosen as the final criterion for selecting the best model. This choice is especially appropriate with imbalanced datasets, where simply focusing on accuracy can result in models that perform poorly on the fraud cases. By choosing the model with the highest F1 score, we prioritize a balance between precision and recall, which is critical in applications like fraud detection or suicide rate classification, where both false positives and false negatives must be minimized to avoid serious consequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: logistic_regression\n",
      "accuracy: 0.9957\n",
      "precision: 0.0000\n",
      "recall: 0.0000\n",
      "f1: 0.0000\n",
      "\n",
      "Model: svm\n",
      "accuracy: 0.9958\n",
      "precision: 0.0000\n",
      "recall: 0.0000\n",
      "f1: 0.0000\n",
      "\n",
      "Model: random_forest\n",
      "accuracy: 0.9976\n",
      "precision: 0.8174\n",
      "recall: 0.5441\n",
      "f1: 0.6533\n",
      "\n",
      "Best model: random_forest\n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'logistic_regression': LogisticRegression(random_state=42),\n",
    "    'svm': SVC(random_state=42),\n",
    "    'random_forest': RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    results[name] = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred)\n",
    "    }\n",
    "    \n",
    "    # Save the model\n",
    "    os.makedirs('../storage/models/artifacts', exist_ok=True)\n",
    "    joblib.dump(model, f'../storage/models/artifacts/{name}.joblib')\n",
    "\n",
    "# Print results\n",
    "for name, metrics in results.items():\n",
    "    print(f\"Model: {name}\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Select the best model based on F1 score\n",
    "best_model = max(results, key=lambda x: results[x]['f1'])\n",
    "print(f\"Best model: {best_model}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the results, the Random Forest model is selected because it has achieved the highest F1 score among all three models. The F1 score, which balances precision and recall, shows that the Random Forest model excels in both identifying positive cases and minimizing errors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data235",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
